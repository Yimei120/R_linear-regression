cv.error.mean  = mean(cv.error.Kfold)))
list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold))
cv.lm(mod3)$cv.error.total
cv.lm(mod2)$cv.error.total
mod2 <- lm(Sales ~ Price + Urban + US, Carseats)
mod3 <- update(mod2, . ~ . - Urban)
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
for(i in 1:n)
cv.error[i] <- mod$model[i, 1] - predict( update(mod, subset = -i),
mod$model[i,])
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm(mod3)$cv.error.total
LOOCV.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod3)
cv.lm(mod2)
mod2
mod3
update(mod3, subset = -1)
update(mod3, subset = -2)
LOOCV.lm(mod3)$cv.error.total
LOOCV.lm
mod3
mod
mod2
LOOCV.lm(mod2)
LOOCV.lm(mod23)
LOOCV.lm(mod3)
LOOCV.lm()
LOOCV.lm
LOOCV.lm(mod3)
LOOCV.lm(mod = mod3)
LOOCV.lm(mod = mod2)
mod3
mod3 <- lm(Sales ~ Price + US, Carseats)
LOOCV.lm(mod = mod3)
mod3 <- update(mod2, . ~ . - Urban)
class(mod3)
LOOCV.lm(mod = mod3)
mod3$model
mod3
update(mod3, subset = -1)
update(mod3, subset = -i)
mod <- update(mod2, . ~ . - Urban)
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
K <- 1
K <- 5
k <- 1
i <- 1
update(mod, subset = -i)
mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
cv.error[i] <- mod$model[i, 1] - predict( update(mod, subset = -i),
mod$model[i,])
cv.error
for(i in 1:n)
cv.error[i] <- mod$model[i, 1] - predict( update(mod, subset = -i),
mod$model[i,])
list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2))
mod
clear(mod)
rm(mod)
mod1 <- lm(crim ~ medv + dis + indus, data = Boston)
mod2 <- lm(Sales ~ Price + Urban + US, Carseats)
mod3 <- update(mod2, . ~ . - Urban)
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
for(i in 1:n)
cv.error[i] <- mod$model[i, 1] - predict( update(mod, subset = -i),
mod$model[i,])
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm(mod3)$cv.error.total
mod3
mod2$model
LOOCV.lm(mod1)
LOOCV.lm(mod2)
LOOCV.lm(mod3)
LOOCV.lm(mod2)
LOOCV.lm(mod3)
LOOCV.lm(mod3)
LOOCV.lm(mod3)
LOOCV.lm(mod3)
i
LOOCV.lm(mod3)
cv.error
formula
LOOCV.lm(mod3)
LOOCV.lm(mod3)
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
for(i in 1:n)
{
mod.loo <- update(mod, subset = -i)
cv.error[i] <- mod$model[i, 1] - predict(mod.loo, mod$model[i,])
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm(mod3)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
i <- 1
# for(i in 1:n)
cv.error[i] <- mod$model[i, 1] - predict( update(mod, subset = -i),
mod$model[i,])
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm(mod3)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
# for(i in 1:n)
i <- 1
cv.error[i] <- update(mod, subset = -i)
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
# for(i in 1:n)
i <- 1
cv.error[i] <- update(mod, subset = -i)
# return( list( cv.error       = cv.error,
#               cv.error.total = sum(cv.error^2),
#               cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod3)$cv.error.total
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
# cv.error <- numeric()
# for(i in 1:n)
i <- 1
cv.error[i] <- update(mod, subset = -i)
# return( list( cv.error       = cv.error,
#               cv.error.total = sum(cv.error^2),
#               cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
# cv.error <- numeric()
# for(i in 1:n)
i <- 1
cv.error <- update(mod, subset = -i)
# return( list( cv.error       = cv.error,
#               cv.error.total = sum(cv.error^2),
#               cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
# cv.error <- numeric()
# for(i in 1:n)
i <- 1
cv.error <- update(mod, subset = -i)
# return( list( cv.error       = cv.error,
#               cv.error.total = sum(cv.error^2),
#               cv.error.mean  = mean(cv.error^2)))
return(cv.error)
}
LOOCV.lm(mod2)$cv.error.total
mod2
update(mod2, subset = -1)
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
# cv.error <- numeric()
# for(i in 1:n)
i <- 1
cv.error <- update(mod, subset = -i)
# return( list( cv.error       = cv.error,
#               cv.error.total = sum(cv.error^2),
#               cv.error.mean  = mean(cv.error^2)))
return(cv.error)
}
LOOCV.lm(mod2)
LOOCV.lm(mod3)
mod2 <- lm(Sales ~ Price + Urban + US, Carseats)
mod3 <- lm(Sales ~ Price + US, Carseats)
LOOCV.lm <- function(mod)
{
# It computes the leave-one-out cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation
cv.error <- numeric()
for(i in 1:n)
cv.error[i] <- mod$model[i, 1] - predict( update(mod, subset = -i),
mod$model[i,])
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.mean  = mean(cv.error^2)))
}
LOOCV.lm(mod2)$cv.error.total
LOOCV.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
cv.lm <- function(mod, K = 5)
{
# It computes the K-fold cross-validation errors for linear model mod
n <- nrow(mod$model)  # number of observation, assuming n is divisible by K
cv.error <- numeric()
cv.error.Kfold <- numeric() # mean test error among each fold
shuffle <- sample.int(n)
for(k in 1:K)
{
subs <- shuffle[(n*(k-1)/K + 1):(n*k/K)]
cv.error[subs] <- mod$model[subs, 1] - predict( update(mod, subset = -subs),
mod$model[subs,])
cv.error.Kfold[k] <- mean( cv.error[subs]^2 )
}
return( list( cv.error       = cv.error,
cv.error.total = sum(cv.error^2),
cv.error.Kfold = cv.error.Kfold,
cv.error.mean  = mean(cv.error.Kfold)))
}
cv.lm(mod2)$cv.error.total
cv.lm(mod3)$cv.error.total
ifelse
?ifelse
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
cv.lm(mod2, 10)$cv.error.total
cv.lm(mod3, 10)$cv.error.total
tic
toc
proc.time()
mod2
mod1 <- lm(crim ~ medv + dis + indus, data = Boston)
summary(mod1)
library(Boston)
library(ISLR)
head(Boston)
library(boot)
head(Boston)
library(MASS)
head(Boston)
mod1 <- lm(crim ~ medv + dis + indus, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ medv + age + indus, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ medv + lstat + indus, data = Boston)
summary(mod1)
mod1 <- lm(crim ~., data = Boston)
summary(mod1)
mod1 <- lm(crim ~ chas + medv + dis, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ ptratio + medv + dis, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ rad + medv + dis, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ rad + medv + dis + zn, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ rad + medv + dis + age, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ rad + indus + dis + age, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ rad + indus + dis, data = Boston)
summary(mod1)
mod1 <- lm(crim ~ rad + age + dis, data = Boston)
summary(mod1)
?confint
install.packages("ISLR")
library(MASS)
library("ISLR")
head(Boston)
mod1 <- lm(crim ~ age + dis + rad, data = Boston)
summary(mod1)
